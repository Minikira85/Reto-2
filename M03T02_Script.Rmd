---
title: "MÓDULO 3: FUNDAMENTOS DE MODELOS ESTADÍSTICOS"
output: html_notebook
---

# MODELO REGRESIÓN LINEAL SIMPLE

```{r}
Prestigio <- read.csv('Prestigio.csv',header=TRUE,stringsAsFactors = TRUE)
```

Ajuste del modelo: $prestigio_i= \beta_0 + \beta_1ingresos_i + \epsilon$.

Visualicemos la distribución conjunta:

```{r}
plot(Prestigio[c('ingresos','prestigio')],pch=16)
```


Se utiliza la función `lm()`:

```{r}
mod1 <- lm(prestigio~ingresos,data=Prestigio)
```

En este caso, notad que se utiliza un objeto de tipo fórmula: $Y\sim X$ (se lee Y es función de X).

Para obtener el resumen del modelo así como algunos contrastes se puede utilizar el método `summary()` aplicado sobre el objeto de tipo `lm`:

```{r}
summary(mod1)
```
Interpretación de los coeficientes:

 - Intercepto: cuando el nivel de ingresos es 0 se espera que el prestigio social sea igual a 27.14 puntos.
 - Efecto de ingresos (pendiente recta de regresión): al incrementar en una unidad el nivel de ingresos, el prestigio aumenta en 0.002897 unidades.


Nótese que cada término tiene un contraste parcial (t) asociado: $H_0:\beta_i=0;  i=0,1.$. Recordad que el contraste en el modelo de regresión lineal simple es $t=\frac{b_i}{EE(b_i)} \sim t_{n-2}$.

Podemos obtener intervalos de confianza para los coeficientes: $b_i\pm t_{\alpha/2,n-2}\times EE(b_i)$.

```{r}
car::Confint(mod1)
```

La primera columna es el coeficiente estimado por mínimos cuadrados (tal y como aparece al ejecutar `summary()`) y las columnas segunda y tercera se corresponden con los límites inferior y superior del intervalo de confianza, respectivamente. Así, el intervalo de confianza para la pendiente de la recta de regresión es $[0.0023;0.0035]$, aproximadamente.

* Gráficos de los efectos:

```{r}
plot(effects::allEffects(mod1))
```

El único predictor del modelo parece que tiene una relación positiva con la variable de respuesta y gracias al contraste parcial sabemos que ésta es significativa.

El modelo es globalmente útil ya que se explica aproximadamente en un $51\%$ la variabilidad del prestigio social percibido. Ahora bien, como se verá en otro apartado, el modelo lineal no está bien especificado.

```{r}
plot(Prestigio[c('ingresos','prestigio')],pch=16)
abline(mod1,col='green')
```


Se pueden obtener predicciones mediante el modelo: argumento interval (confidence o prediction)

* Respuesta media:

```{r}
x<- with(Prestigio,seq(min(ingresos),max(ingresos),1))
preds <- predict(mod1,newdata=list(ingresos=x),interval='confidence')

plot(Prestigio[c('ingresos','prestigio')],pch=16,ylim=c(15,100))
abline(mod1,col='green')

lines(x, preds[,2], col="blue", lty=2)
lines(x, preds[,3], col="blue", lty=2)
```


* Respuesta individual:

```{r}
x<- with(Prestigio,seq(min(ingresos),max(ingresos),1))
preds <- predict(mod1,newdata=list(ingresos=x),interval='prediction')

plot(Prestigio[c('ingresos','prestigio')],pch=16,ylim=c(15,100))
abline(mod1,col='green')

lines(x, preds[,2], col="blue", lty=2)
lines(x, preds[,3], col="blue", lty=2)
```


* Algunas funciones extractoras aplicadas a summary() pueden ser de utilidad:

```{r}
# RMSE
summary(mod1)$sigma

# R2
summary(mod1)$r.squared

```


# MODELO REGRESIÓN LINEAL MÚLTIPLE

* Podemos incorporar más predictores en el modelo lineal, por ejemplo:

$prestigio_i= \beta_0 + \beta_1ingresos_i +\beta_2porcentaje.mujeres_i+ \epsilon$


```{r}
mod2 <- lm(prestigio~ingresos+porc.mujeres,data=Prestigio)
summary(mod2)
```

Los coeficientes se interpretan como efectos parciales (el cambio esperado en la respuesta al aumentar una unidad el predictor, manteniendo constantes todos los otros predictores).

Podemos obtener intervalos de confianza para los coeficientes de este nuevo modelo:

```{r}
car::Confint(mod2)
```

Gráficos de los efectos del modelo 2:

```{r}
plot(effects::allEffects(mod2))
```

El modelo es globalmente útil ya que se explica aproximadamente en un $55\%$ la variabilidad del prestigio social percibido.

* Podemos estimar betas estandarizadas (son comparables entre sí en el caso de los predictores) si previamente transformamos los predictores con la expresión $z_i=\frac{x_i-\bar x}{s_x}$:

```{r}
Zscores <- sapply(Prestigio[,c('prestigio','ingresos','porc.mujeres')],scale)
colnames(Zscores) <- c('Z.prestigio','Z.ingresos','Z.mujeres')
datosZ <- data.frame(Zscores)

mod.Z <- lm(Z.prestigio ~ Z.ingresos + Z.mujeres, data=datosZ)
summary(mod.Z)
```
* Regresión jerárquica: permite comparar modelos anidados, un modelo completo con $p$ predictores y un modelo reducido con $k$ predictores ($p>k$). Así se podrá tomar una decisión sobre $H_0:\beta_{k+1}=\beta_{k+2}=\dots=\beta_p$.


```{r}
anova(mod1,mod2)
```

El modelo completo (incluyendo ingresos y porcentaje de mujeres) reduce significativamente mejor la suma de residuos al cuadrado en comparación al modelo restringido, que incluye únicamente ingresos.

* Se pueden incorporar predictores cualitativos mediante variables artificiales:

```{r}
mod3 <- lm(prestigio~ingresos+porc.mujeres+tipo,data=Prestigio)
summary(mod3)
```
Dado que tenemos una predictor categórico, debe recordarse que el intercepto incorpora la predicción para la categoría de referencia (en este caso bc, blue collar). Y por tanto los coeficientes de las variables artificiales para prof y wc se interpretan como la diferencia de éstas respecto a la categoría de referencia.

```{r fig.width=10,fig.height=10}
plot(effects::allEffects(mod3))
```


* Tabla de sumas de cuadrados para el modelo lineal resultante, nos permite en el caso de que el predictor tenga más de un término asociado llevar a cabo un contraste global:

```{r}
car::Anova(mod3)
```

¿Podemos eliminar porc.mujeres del modelo? Regresión jerárquica:

```{r}
mod4 <- update(mod3,.~.-porc.mujeres)

anova(mod4,mod3)
```

No hay diferencias significativas entre el modelo completo y el reducido por lo que escogeremos éste último (más parsimonioso).
Nótese que el valor de probabilidad asociado al contraste F de la regresión jerárquica coincide con la del contraste parcial obtenido en el summary() de modelo 3.


* Modelos no aditivos: en los que encontramos interacciones entre algunos regresores.

```{r}
mod5 <- lm(prestigio~tipo+ingresos*porc.mujeres,data=Prestigio)
summary(mod5)
```

```{r fig.width=10,fig.height=10}
plot(effects::allEffects(mod5))
```

Según este nuevo modelo, el efecto de ingresos sobre el prestigio percibido depende del porcentaje de mujeres en la profesión. Paralelamente, el efecto del porcentaje de mujeres también depende de cómo se combine con el nivel de ingresos.

¿Realmente mejora el ajuste el término interactivo? Parece ser que no...

```{r}
 anova(mod4,mod5)
```



# MODELOS POLINÓMICOS

* Como se observó anteriormente, parece que la relación entre ingresos y prestigio es no lineal. Podemos ajustar por esta razón una relación cuadrática (polinomio de grado 2): $Y=\beta_0+\beta_1X+\beta_2X^2 +\epsilon$

```{r}
mod6 <- lm(prestigio~poly(ingresos,2,raw=TRUE)+tipo,data=Prestigio)
summary(mod6)
```
```{r}
plot(effects::allEffects(mod6))
```

* Si ajustamos un polinomio de grado 3, $Y=\beta_0+\beta_1X+\beta_2X^2 +\beta_3X^3 +\epsilon$, ¿mejora el ajuste?

```{r}
mod7 <- lm(prestigio~poly(ingresos,3,raw=TRUE)+tipo,data=Prestigio)
anova(mod6,mod7)
```


* Polinomio ortogonales: mejoran algunos problemas en la estimación pero no son interpretables directamente los coeficientes

```{r}
mod8 <- lm(prestigio~poly(ingresos,2,raw=FALSE)+tipo,data=Prestigio)
summary(mod8)
```

* Ajustes por saltos (step functions):

Estimamos el valor del prestigio en 4 intervalos:
(586,6.93e+03] (6.93e+03,1.32e+04] (1.32e+04,1.96e+04] (1.96e+04,2.59e+04]

El primer intervalo quedará incorporado en el intercepto, pues se trata de la categoría de referencia en este caso.


```{r}
mod9 <- lm(prestigio~cut(ingresos,4)+tipo,data=Prestigio)
summary(mod9)
```

```{r}
plot(effects::allEffects(mod9))
```


* Modelo con splines naturales cúbicos:

Se puede comprobar que este modelo ajusta mejor que el obtenido con step functions...

```{r}
mod10 <- lm(prestigio~ splines::ns(ingresos,knots=c(8000))+tipo,
             data = Prestigio)
summary(mod10)
```

```{r}
plot(effects::allEffects(mod10))
```


# TRANSFORMACIONES Y MODELOS LOGARÍTMICOS

* Datos de mortalidad infantil: con el diagrama de densidad se observa claramente la asimetría positiva.

```{r}
UN <- read.csv('UN.csv',header=TRUE)
plot(density(na.omit(UN$infant.mortality),bw = 6),
     xlim=c(-30,200),xlab='Tasa mortalidad infantil (x 1000)',lwd=2,
     ylab='Densidad',main='')
rug(UN$infant.mortality)
```

* Algunas transformaciones y el efecto de éstas sobre la distribución:

```{r fig.width=10,fig.height=10}
datos <- data.frame(T1=-(scale(UN$infant.mortality))^(-1),
           T2=-(scale(UN$infant.mortality))^(-.5),
           T3=log(scale(UN$infant.mortality,10)),
           T4=(scale(UN$infant.mortality))^(.5),
           T5=scale(UN$infant.mortality))
boxplot(datos,ylim=c(-10,4.7),yaxt='n',xaxt='n')
axis(1,at=1:5,labels=c(expression(-X^{-1}),
                       expression(-X^{-1/2}),
                       expression(log[10](X)),
                       expression(X^{1/2}),
                       expression(X)))
```

* Al utilizar la transformación logarítmica se simetriza bastante la distribución:

```{r fig.width=10,fig.height=10}
plot(density(na.omit(log(UN$infant.mortality)),bw = .25),
     xlab=expression(paste(log[e],'(Tasa mortalidad infantil)')),lwd=2,
     ylab='Densidad',main='')
rug(na.omit(log(UN$infant.mortality)))
```

* El modelo predictivo para la tasa de mortalidad utilizando el PIB no puede ser lineal, al menos no sin una transformación de los datos:

```{r fig.width=10,fig.height=10}
with(UN,car::scatterplot(gdp,infant.mortality,label=row.names(UN),
                    xlab='PIB',ylab='Mortalidad'))
```

* Una posible transformación es la logarítmica (ver regla de Mosteller y Tukey):

```{r fig.width=10,fig.height=10}
with(UN,car::scatterplot(log(gdp),log(infant.mortality),label=row.names(UN),
                    xlab='log(PIB)',ylab='log(Mortalidad)'))
```


* Otra posibilidad es utilizar la transformación de Box-Cox:

```{r}
BC <- MASS::boxcox(infant.mortality~gdp,data=UN)
lambda <- BC$x[which.max(BC$y)]
```


```{r fig.width=10,fig.height=10}
boxcoxT <- function(x,lamb){(x ^ lamb - 1) / lamb}
BCscores <- sapply(UN[,c('infant.mortality','gdp')],boxcoxT,lamb=lambda)
colnames(BCscores) <- c('BC.infant','BC.GDP')
datosBC <- data.frame(BCscores)

with(datosBC,car::scatterplot(BC.GDP,BC.infant,label=row.names(UN),
                    xlab='PIB',ylab='Mortalidad'))
```

* Modelo lineal-lineal:

```{r}
colnames(UN) <- c('Mortalidad','PIB')
summary(lm(Mortalidad~PIB,data=UN))
```
* Modelo lineal-log:

```{r}
summary(lm(Mortalidad~log(PIB),data=UN))
```


* Modelo log-lineal:

```{r}
summary(lm(log(Mortalidad)~PIB,data=UN))
```

* Modelo log-log:

```{r}
summary(lm(log(Mortalidad)~log(PIB),data=UN))
```

* Pseudo-R2: permite comparar modelos lineales con log-lineales (o log-log):

```{r}
UN <- na.omit(UN)
logmod <- lm(log(Mortalidad)~log(PIB),data=UN)
fit.y <- exp(predict(logmod))
Rsq.ln <- 1-sum((UN$Mortalidad-fit.y)^2)/sum((UN$Mortalidad-mean(UN$Mortalidad))^2)
cat('Pseudo-R^2 para el modelo log-log: ' ,round(Rsq.ln,4))
```


# SELECCIÓN, REGULARIZACIÓN Y REDUCCIÓN DE LA DIMENSIONALIDAD

```{r}
diabetes <- read.csv('diabetes.csv',header=TRUE,stringsAsFactors = TRUE)
```

* Con la funcióń regsubsets, se pueden estimar todas las posibles combinaciones de modelos para los distintos niveles de complejidad y seleccionar el nivel óptimo en función de varios criterios ($R^2_{Ajustada}$, Cp de Mallow, BIC, ...)

```{r}
if(!require(leaps)) install.packages('leaps')
library(leaps)

regsub.full <- regsubsets(glyhb ~ .-id,nbest=1, data=diabetes,nvmax=18)
mysum <- summary(regsub.full)

plot(regsub.full,scale='adjr2') # Or Cp, bic
plot(regsub.full,scale='Cp')
plot(regsub.full,scale='bic')

plot(mysum$adjr2,type='l',xlab='Complejidad',main='Adj-R2')
points(mysum$adjr2,pch=16)
abline(v=which.max(mysum$adjr2),col='red',lty=2)
text(x=5.5, y=0.69,labels = paste('Max en k =',which.max(mysum$adjr2),' términos',sep=''),col='red')

plot(mysum$bic,type='l',xlab='Complejidad',main='bic')
points(mysum$bic,pch=16)
abline(v=which.min(mysum$bic),col='red',lty=2)
text(x=8, y=-120,labels = paste('Min en k =',which.min(mysum$bic),' términos',sep=''),col='red')

plot(mysum$cp,type='l',,xlab='Complejidad',main='Mallows Cp')
points(mysum$cp,pch=16)
abline(v=which.min(mysum$cp),col='red',lty=2)
text(x=12, y=20,labels = paste('Min en k =',which.min(mysum$cp),' términos',sep=''),col='red')

```

## Eliminación hacia atrás:
El modelo inicial es el modelo completo.

```{r warning=FALSE,message=FALSE}
if(!require(RcmdrMisc)) install.packages('RcmdrMisc')
library(RcmdrMisc)

mod.full <- lm(glyhb~.-id,data=diabetes)

stepwise(mod.full, direction='backward', criterion='BIC') # trace=0 para evitar imprimir los pasos intermedios

```

## Sección hacia adelante:
El inicio es el modelo nulo.

```{r warning=FALSE,message=FALSE}
stepwise(mod.full, direction='forward', criterion='BIC')
```

## Validación cruzada

### Muestra de validación

```{r}
# Código adaptado de Gareth et Al. (2015)

# Dividir la muestra en muestra de entrenamiento y de test:
set.seed(123)
train <- sample(c(T,F),nrow(diabetes),replace=TRUE)
test <- !train
# Entrenar el modelo con la muestra de entrenamiento
regfit.best <- regsubsets(glyhb~.-id,data=diabetes[train,],nvmax=18)

# Validar el modelo con la muestra de test
test.mat <- model.matrix(glyhb~.-id,data=diabetes[test,])
val.errors <- array(NA,)
for(i in 1:18){
  coefi <- coef(regfit.best,id=i)
  pred <- test.mat[,names(coefi)]%*%coefi
  val.errors[i] <- mean((diabetes$glyhb[test]-pred)^2)
}

min <- which.min(val.errors)

plot(val.errors,type='l',xlab='Complejidad',main='CV Muestra de validación')
points(val.errors,pch=16)
abline(v=which.min(val.errors),col='red',lty=2)
text(15,max(val.errors),labels = paste('Min en k =',min,' términos',sep=''),col='red')


# Estimar el modelo con el número óptimo de regresores con la muestra completa

regfit.best <- regsubsets(glyhb~.-id,data=diabetes,nvmax=min)
coef(regfit.best,min)
```


### Validación K-FOLD (y Leave-One-Out) 


```{r}
# Código adaptado de Gareth et Al. (2015)

# Creamos en primer lugar un método predict para regsubsets

predict.regsubsets <- function(object,newdata,id,...){
      form <- as.formula(object$call[[2]])
      mat <- model.matrix(form,newdata)   
      coefi <- coef(object,id=id)       
      xvars <- names(coefi)               
      mat[,xvars]%*%coefi             
}

# Creación y asignación de los individuos a los folds: k= 5, 10, ..., nrow(diabetes)
# Si se especifica el número de filas del data.frame se lleva a cabo validación con Leave-One-Out 
k <- 50

set.seed(123)   
if (k != nrow(diabetes)) { 
  folds <- sample(1:k, nrow(diabetes), replace = TRUE)
} else {
  folds <- 1:k
  }
cv_errors <- matrix(NA, k, 18, dimnames = list(NULL, paste(1:18)))

# Estimación del MSE mediante validación cruzada
for(j in 1:k){
    
    # La muestra de entrenamiento es la muestra completa menos los datos del j-esimo fold
    best_fit <- regsubsets(glyhb~.-id, data = diabetes[folds!=j,], nvmax=18)
    
    # Cada valor de i representa el número de regresores (nivel de complejidad del modelo)
    for(i in 1:18){
        
        # Predicciones para el j-ésimo fold usando el subconjunto con i términos
        pred <- predict(best_fit, diabetes[folds==j,], id=i)
        
        # Calcular MSE y guardarlo
        cv_errors[j,i] <- mean((diabetes$glyhb[folds==j]-pred)^2)
    }
}

# Calcular la media de todos los folds para cada nivel de complejidad
mean_cv_errors <- apply(cv_errors, 2, function(x) mean(x,na.rm=TRUE))

# Hallar el nivel de complejidad que minimiza el error de cross-validación
min <- which.min(mean_cv_errors)

# Gráfico del error de cross-validación

plot(mean_cv_errors,type='l',xlab='Complejidad',main=ifelse(k==nrow(diabetes),'LOO Cross-Validation',paste(k,'-Fold CV',sep='')))
points(mean_cv_errors,pch=16)
abline(v=which.min(mean_cv_errors),col='red',lty=2)
text(15,max(mean_cv_errors),labels = paste('Min en k =',min,' términos',sep=''),col='red')

# Obtener el mejor modelo con el número de términos óptimo así como las estimaciones de los parámetros para la muestra completa

reg_best <- regsubsets(glyhb~.-id, data = diabetes, nvmax = min)
coef(reg_best, min)

```

### Ridge Regression

* La función glmnet() del paquete glmnet nos permite llevar a cabo el procedimiento de regularización.
* El argumento alpha=0 se corresponde con el procedimiento de la Ridge Regression.
* El parámetro lambda, controla el grado de regularización. Se puede llevar a cabo un procedimiento de validación cruzada para hallar el nivel óptimo.

```{r}
if(!require(glmnet)){ install.packages('glmnet')
  library(glmnet)}

grid <- 10^seq(-3,2,length=100)

# Hot encoding

factores <- model.matrix(diabetes$glyhb~diabetes$location+diabetes$gender+diabetes$frame)[,-1]

matrizMODS <- as.matrix(data.frame(factores,diabetes[colnames(diabetes)[c(2:5,8,10,11,13:19)]]))

mod.ridge <- glmnet(matrizMODS,as.matrix(diabetes['glyhb']),alpha=0,lambda=grid)

MATRIZ.COEFS <- matrix(NA,nrow=dim(coef(mod.ridge))[2],dim(coef(mod.ridge))[1]-1)
for(i in 1:dim(coef(mod.ridge))[2]){
  MATRIZ.COEFS[i,] <- coef(mod.ridge)[-1,i]
}

par(mar=c(4,5,2,2))
matplot(MATRIZ.COEFS[order(mod.ridge$lambda,decreasing=FALSE),], type = 'l',lwd=1.5,
        xaxt='n',xlab=expression(lambda),ylab=expression(hat(beta)))
axis(1,at=seq(1,100,length=5),labels= round(rev(mod.ridge$lambda)[seq(1,100,length=5)],3))
```

```{r}
# TRAINING Y TEST
set.seed(123)
train <- sample(1:nrow(diabetes),.6*nrow(diabetes))
test <- (-train)


# MODELO

ridge.mod <- glmnet(matrizMODS[train,],as.matrix(diabetes['glyhb'])[train],alpha=0,lambda=grid)
# Un valor de lambda cualquiera para RMSE test
ridge.pred <- predict(ridge.mod,s=1.2,newx=matrizMODS[test,])
mean((diabetes[test,'glyhb']-ridge.pred)^2)


# CV lambda

set.seed(123)
cv.out <- cv.glmnet(matrizMODS[train,],as.matrix(diabetes['glyhb'])[train],alpha=0)
par(mar=c(4,4,2,2))
plot(cv.out,ylab='MSE')
```

```{r}
ridge.pred <- predict(ridge.mod,s=cv.out$lambda.min,newx=matrizMODS[test,])
mean((diabetes[test,'glyhb']-ridge.pred)^2) # RMSE para el valor de lambda óptimo

# Modelo datos completos para los coeficientes 2 escenarios: óptimo (min) y min + 1SE

ridge.mod.out <- glmnet(matrizMODS,as.matrix(diabetes['glyhb']),alpha=0,lambda=grid)
ridge.coef1 <- predict(ridge.mod.out,type='coefficients',s=cv.out$lambda.min)
ridge.coef2 <- predict(ridge.mod.out,type='coefficients',s=cv.out$lambda.1se)
MAT <- cbind(ridge.coef,ridge.coef2)
dimnames(MAT)[[2]] <- c('Min','Min1SE')
MAT
```

### LASSO

* Argumento alpha=1 nos pemite llevar a cabo el procedimiento LASSO.

```{r}
mod.lasso <- glmnet(matrizMODS,as.matrix(diabetes['glyhb']),alpha=1,lambda=grid)

MATRIZ.COEFS <- matrix(NA,nrow=dim(coef(mod.lasso))[2],dim(coef(mod.lasso))[1]-1)
for(i in 1:dim(coef(mod.lasso))[2]){
  MATRIZ.COEFS[i,] <- coef(mod.lasso)[-1,i]
}

par(mar=c(4,5,2,2))
matplot(MATRIZ.COEFS[order(mod.lasso$lambda,decreasing=FALSE),], type = 'l',lwd=1.5,
        xaxt='n',xlab=expression(lambda),ylab=expression(hat(beta)))
axis(1,at=seq(1,100,length=5),labels= round(rev(mod.lasso$lambda)[seq(1,100,length=5)],3))


# TRAINING Y TEST
set.seed(123)
train <- sample(1:nrow(diabetes),.6*nrow(diabetes))
test <- (-train)

# MODELO

lasso.mod <- glmnet(matrizMODS[train,],as.matrix(diabetes['glyhb'])[train],alpha=1,lambda=grid)
# Un valor de lambda cualquiera para RMSE test
lasso.pred <- predict(lasso.mod,s=1.2,newx=matrizMODS[test,])
mean((diabetes[test,'glyhb']-lasso.pred)^2)


# CV lambda

set.seed(123)
cv.out <- cv.glmnet(matrizMODS[train,],as.matrix(diabetes['glyhb'])[train],alpha=1)
par(mar=c(4,4,2,2))
plot(cv.out,ylab='MSE')


lasso.pred <- predict(lasso.mod,s=cv.out$lambda.min,newx=matrizMODS[test,])
mean((diabetes[test,'glyhb']-lasso.pred)^2)

# Modelo datos completos para los coeficientes

lasso.mod.out <- glmnet(matrizMODS,as.matrix(diabetes['glyhb']),alpha=1,lambda=grid)
lasso.coef <- predict(lasso.mod.out,type='coefficients',s=cv.out$lambda.min)

lasso.coef <- predict(lasso.mod.out,type='coefficients',s=cv.out$lambda.1se)
lasso.coef
```


### PCR

* El procedimiento de regresión con componentes principales está implementado en la función pcr del paquete pls.
* El argumento scale=TRUE permite estandarizar los predictores.


```{r}
if(!require(pls)){install.packages('pls')
  library(pls)
}

# Validación cruzada para decidir el número óptimo de compenentes
set.seed(123)
pcr.mod <- pcr(glyhb~.-id,data=diabetes[train,],scale=TRUE,validation='CV')

summary(pcr.mod)

validationplot(pcr.mod,val.type='MSEP',xlab='Nº de componentes',main='')

# PCR con 10 componentes y estimación del MSE
x <- model.matrix(glyhb~.-id,data=diabetes)[,-1]

pcr.pred <- predict(pcr.mod,newdata=x[test,],ncomp=10)
mean((pcr.pred-diabetes[test,'glyhb'])^2)
```


### PLS

```{r}

set.seed(123)
pls.mod <- plsr(glyhb~.-id,data=diabetes[train,],scale=TRUE,validation='CV')

summary(pls.mod)

validationplot(pls.mod,val.type='MSEP',xlab='Nº de componentes',main='')


x <- model.matrix(glyhb~.-id,data=diabetes)[,-1]

pls.pred <- predict(pls.mod,newdata=x[test,],ncomp=4)
mean((pls.pred-diabetes[test,'glyhb'])^2)
```


# DIAGNÓSTICO MODELOS LINEALES

```{r}
Prestigio <- read.csv('Prestigio.csv',header=TRUE,stringsAsFactors = TRUE)
```

## Gráficos de residuos

```{r}
mod1 <- lm(prestigio~ingresos+porc.mujeres,data=Prestigio)
plot(mod1)
```
### Linealidad

En este caso, se rechaza la $H_0$ y por tanto no se cumple el supuesto. La solución pasa por incluir términos polinómicos en el caso de ingresos.

```{r}
par(mfrow=c(1,2))
plot(mod1,which = c(1,3))

library(lmtest)
resettest(prestigio~ingresos+porc.mujeres, power=2:3, type="regressor", data=Prestigio)

# Component residuals plots para efectos principales

crPlots(mod1, smooth=list(span=0.5))
```

### Normalidad

En este caso, se rechaza la $H_0$ y por tanto no se cumple el supuesto. Se puede buscar alguna transformación que simetrice la distribución.

```{r}
par(mfrow=c(1,2))
hist(mod1$residuals)
plot(mod1,which = 2)

shapiro.test(mod1$residuals)

#ks.test(residuals(mod1),'pnorm',mean=0,sd=summary(mod1)$sigma)
```

### Homogeneidad de varianza del error

En este caso, se rechaza la $H_0$ y por tanto no se cumple el supuesto. Se puede buscar una transformación estabilizadora.

```{r}
par(mfrow=c(1,2))
plot(mod1,which=c(1,3))

bptest(prestigio ~ ingresos+porc.mujeres, varformula = ~ fitted.values(mod1), studentize=FALSE, data=Prestigio)
```

### Independencia de los residuales

Existe dependencia serial por lo que el modelo lineal con mínimos cuadrados no es adecuado.

```{r}
acf(mod1$residuals)

set.seed(123)
durbinWatsonTest(mod1,max.lag=10)
```

### MULTICOLINEALIDAD

En este nuevo modelo parece que puede haber un problema de multicolinealidad pero se solventa estandarizando una de las variables implicadas en la interacción.

```{r}
mod2 <- lm(prestigio~poly(ingresos,2,raw=FALSE)+porc.mujeres*educacion,data=Prestigio)
car::vif(mod2)
```

```{r}
mod2 <- lm(prestigio~poly(ingresos,2,raw=FALSE)+porc.mujeres*scale(educacion),data=Prestigio)
car::vif(mod2)
```



# INFLUENCIA

## OUTLIERS

### Respuesta

```{r}
influenceIndexPlot(mod2, id=list(method="y", n=3), vars=c("Studentized"))
# Se puede utilizar funciones extractoras como rstudent() y rstandard()
```



### Predictores

```{r}
influenceIndexPlot(mod2, id=list(method="y", n=3), vars=c("hat"))
# Función extractora hatvalues()
```



### Influencia

```{r}

influenceIndexPlot(mod2, id=list(method="y", n=3), vars=c("Cook"))
# Función extractora: cooks.distance()

influencePlot(mod2, id=list(method="noteworthy", n=3))
avPlots(mod2, id=list(method="mahal", n=2)) ## Added-variables plot
outlierTest(mod2)
```
