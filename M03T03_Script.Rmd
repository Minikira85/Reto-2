---
title: "MÓDULO 3: FUNDAMENTOS DE MODELOS ESTADÍSTICOS"
output: html_notebook
---

```{r warning=FALSE,message=FALSE}
if(!require(DescTools)) {install.packages("DescTools")
require(DescTools)}

if(!require(ggplot2)) {install.packages("ggplot2")
require(ggplot2)}

if(!require(effects)) {install.packages("effects")
require(effects)}

if(!require(car)) {install.packages("car")
require(car)}

if(!require(Hmisc)) {install.packages("Hmisc")
require(Hmisc)}


if(!require(ROCR)) {install.packages("ROCR")
require(ROCR)}

```

# DESCRIPTIVO PRELIMINAR

```{r warning=FALSE,message=FALSE}
Contraceptive <- read.csv('Contraceptive.csv',header=TRUE,stringsAsFactors = TRUE)

summary(Contraceptive)

# Contraceptive$cuse
describe(as.factor(Contraceptive$cuse))

```
La variable de respuesta es cuse (usa o no métodos anticonceptivos). En este caso casi un $69%$ de la muestra no los utiliza. Se trata de construir un modelo de clasificación para predecir esta variable.

# MODELOS REGRESIÓN LOGÍSTICA

## Modelo con efectos principales

Utilizaremos la función `glm()` que como veremos es muy similar a la función`lm()` para modelos lineales. Debemos especificar la función de enlace, mediante el argumento `family` que en este caso, dado que utilizaremos la función logística, es `binomial`. 

```{r echo=FALSE,warning=FALSE,message=FALSE}
mod1 <- glm(cuse~.,Contraceptive,family=binomial)
summary(mod1)
```
Recordad el tema de las variables artificiales para incorporar predictores de tipo categórico. Por ejemplo, en el caso de la edad se tienen 4 grupos de edad (<25; 25-29; 30-39 y 40-49) y la categoría de referencia es <25. Por lo que el coeficiente estimado para 25-29 se interpreta como la diferencia en el log-odds entre el grupo de referencia y este grupo de edad (éste último tiene una log-odds de uso 0.39 unidades mayor, esto es, es más probable el uso de métodos anticonceptivos).

El intercepto incorpora la estimación para todas las categorías de referencia (edad <25 años, nivel educativo alto y no deseo de tener más hijos).

En las dos últimas columnas están los tests de Wald parciales para cada uno de los términos del modelo.


* Efectos:

```{r fig.width=10,fig.height=10}
plot(allEffects(mod1))
```

De estos gráficos se puede concluir que es más probable utilizar métodos anticonceptivos cuando se es más mayor, se tiene un nivel educativo alto y no se desean más hijos comparativamente a las otras categorías en sus respectivos casos.

### Contrastes globales: Tests basado en la razón de verosimilitudes y de Wald

```{r  echo=FALSE,warning=FALSE,message=FALSE}
Anova(mod1,"LR",type='II')
```

```{r  echo=FALSE,warning=FALSE,message=FALSE}
Anova(mod1,"Wald",type='II')
```

En ambos tests concluiríamos que todos los predictores son de utilidad para clasificar a las mujeres en función del uso de anticonceptivos.

## Modelos con interacciones

```{r  echo=FALSE,warning=FALSE,message=FALSE}
mod2 <- glm(cuse~education+age*morechild,Contraceptive,family=binomial)
summary(mod2)
```

```{r  echo=FALSE,warning=FALSE,message=FALSE,fig.width=10,fig.heigth=10}
plot(allEffects(mod3))
```



## Selección de variables con modelos lineales generalizados

```{r  echo=FALSE,warning=FALSE,message=FALSE}
n<-nrow(Contraceptive)
mod3 <- step(mod2,direction = 'both',trace=FALSE,criterion='BIC')
summary(mod3)
```

No se ha eliminado ningún regresor del modelo original.

## Test de devianza para comparar modelos anidados

```{r  echo=FALSE,warning=FALSE,message=FALSE}
anova(mod1, mod3, test="Chisq")
```


El modelo completo (efectos principales e interacción) es significativamente mejor que el reducido (sólo efectos principales).

## Multicolinealidad

```{r  echo=FALSE,warning=FALSE,message=FALSE}
vif(mod3)
```

En aquellos casos en los que la columna Df sea mayor que 1 se interpretará el valor de la segunda columna. En este caso, no se aprecian valores consistentes con un problema grave de multicolinealidad.


## Valores de Pseudo-R2

```{r  echo=FALSE,warning=FALSE,message=FALSE}
PseudoR2(mod3,which='all')[c(1,3)]
PseudoR2(mod3,which='all')[c(4,8)]
```

## Influencia

```{r  echo=FALSE,warning=FALSE,message=FALSE}
influenceIndexPlot(mod3,id.n=2)
```


## Rendimiento del modelo: Curva ROC

```{r  echo=FALSE,warning=FALSE,message=FALSE}
pred <- prediction(predict(mod3,type="response"),Contraceptive$cuse)
perf <- performance( pred, "tpr", "fpr" )
plot( perf,col='blue' )
abline(0,1,col='red',lty=2)
```

# Área bajo la curva (AUC)

```{r echo=FALSE,warning=FALSE,message=FALSE}
str(performance(pred,'auc'))
```

El rendimiento del modelo es malo.

## Matrices de confusión

Podemos construir matrices de confusión utilizando un punto de corte para la probabilidad estimada a partir del modelo, por ejemplo, $s=0.5$:

```{r}

ifelse(predict(mod3,type="response")>=0.5,1,0)->val.pred

CONFMAT <- table(val.pred,Contraceptive$cuse)[2:1,2:1] # Genero una tabla y|x=1/y|x=0 y y=1/y=0, por filas y columnas

CONFMAT
```

Puedo calcular distintos indicadores de rendimiento a partir de esta estructura de matriz de confusión (por filas las predicciones y por columnas las observaciones reales; en orden 1-0):

```{r}
rendimiento <- function(tabla){
  Se <- tabla[1,1]/colSums(tabla)[1]
  Es <- tabla[2,2]/colSums(tabla)[2]
  Fo <- 1-Es
  Ex <- sum(diag(tabla))/sum(tabla)
  Pr <- tabla[1,1]/rowSums(tabla)[1]
  F1 <- psych::harmonic.mean(c(Se,Pr))
  rend <- c(Se,Es,Fo,Ex,Pr,F1)
  names(rend) <- c('Sensibilidad','Especificidad','Fall out','Exactitud','Precisión','F1')
  rend
}

rendimiento(CONFMAT)
```


# ANÁLISIS DISCRIMINANTE

## Lineal

Utilizaremos una muestra de entrenamiento y otra de test (para evaluar el rendimiento).

```{r}
library(MASS)


set.seed(123)
train <- sample(1:nrow(Contraceptive),nrow(Contraceptive)*.70,replace=FALSE)
test <- -train

modelo <- lda(cuse ~ ., data=Contraceptive[train,])
modelo
```
```{r}
plot(modelo)
```

```{r}
lda.clase <- predict(modelo,Contraceptive[test,])$class
CONFMAT.lda <- table(lda.clase,Contraceptive[test,'cuse'])[2:1,2:1]
rendimiento(CONFMAT.lda)
```


## Cuadrático

```{r}
modelo2 <- qda(cuse ~ ., data=Contraceptive[train,])
modelo2
```
```{r}
qda.clase <- predict(modelo2,Contraceptive[test,])$class
CONFMAT.qda <- table(qda.clase,Contraceptive[test,'cuse'])[2:1,2:1]
rendimiento(CONFMAT.qda)
```

El modelo discriminante cuadrático mejora al lineal e incluso al glm (en este caso se entrenó y se testó con todos los datos por lo que es probable que el rendimiento del modelo logístico este sobreestimado).

# NAIVE BAYES

```{r}
set.seed(123)
train <- sample(1:nrow(Contraceptive),nrow(Contraceptive)*.70,replace=FALSE)
test <- -train

modelo <- naiveBayes(cuse~.,data=Contraceptive[train,])
modelo
```

```{r}
NB.clase <- predict(modelo,Contraceptive[test,])
CONFMAT.NB <- table(NB.clase,Contraceptive[test,'cuse'])[2:1,2:1]
rendimiento(CONFMAT.NB)
```

