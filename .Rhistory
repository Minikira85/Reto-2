# ---- Análisis descriptivo (Carlos Dario) ----
# ---- Carga y limpieza inicial de datos ----
library(readr)
library(dplyr)
archivos <- list.files("DataSets", pattern = "\\.csv$", full.names = TRUE)
datos <- archivos |>
lapply(read_csv, col_types = cols(.default = "c")) |>
bind_rows() |>
mutate(
age = as.numeric(age)
)
=======
#Regresión logística
library(tidyverse)
library(effects)
#Regresión logística
library(tidyverse)
install(effects)
#Regresión logística
library(tidyverse)
install.packages(effects)
#Regresión logística
library(tidyverse)
install.packages("effects")
library(effects)
library(car)
#Regresión logística
library(tidyverse)
install.packages("effects")
library(tidyverse)
# Cargar datos de entrenamiento
train <- read_csv("train.csv")
# Comprobar estructura de los datos
glimpse(train)
# Identificar tipos de variables automáticamente
# Variables numéricas
vars_numericas <- train |>
select(where(is.numeric)) |>
names()
# Variables categóricas (no numéricas)
vars_categoricas <- train |>
select(where(~ !is.numeric(.))) |>
names()
# Comprobación
vars_numericas
vars_categoricas
# Análisis descriptivo tabular
# Resumen estadístico de variables numéricas
summary(train |> select(all_of(vars_numericas)))
# Tablas de frecuencia de variables categóricas
lapply(
train |> select(all_of(vars_categoricas)),
table
)
# Análisis descriptivo gráfico
# Histogramas de variables numéricas
train |>
pivot_longer(
cols = all_of(vars_numericas),
names_to = "variable",
values_to = "valor"
) |>
ggplot(aes(x = valor)) +
geom_histogram(
bins = 30,
fill = "steelblue",
color = "white"
) +
facet_wrap(~variable, scales = "free") +
labs(
title = "Distribución de las variables numéricas",
x = "Valor",
y = "Frecuencia"
)
# Diagramas de barras de variables categóricas
train |>
pivot_longer(
cols = all_of(vars_categoricas),
names_to = "variable",
values_to = "valor"
) |>
ggplot(aes(x = factor(valor))) +
geom_bar(fill = "darkorange") +
facet_wrap(~variable, scales = "free_x") +
labs(
title = "Distribución de las variables categóricas",
x = "Categoría",
y = "Frecuencia"
)
# Pregunta 2: Análisis bivariado
library(tidyverse)
# Cargar datos de entrenamiento
train <- read_csv("train.csv")
# Eliminar variable de registro si existe
if ("id" %in% names(train)) {
train <- train |> select(-id)
}
# Definir variable respuesta
response_var <- "Satisfaction"
# -------------------------
# Identificar tipos de variables
# -------------------------
vars_numericas <- train |>
select(where(is.numeric)) |>
names() |>
setdiff(response_var)
vars_categoricas <- train |>
select(where(~ !is.numeric(.))) |>
names() |>
setdiff(response_var)
# Análisis bivariado
# 1. Variables numéricas vs Satisfaction
train |>
pivot_longer(
cols = all_of(vars_numericas),
names_to = "variable",
values_to = "valor"
) |>
ggplot(aes(x = factor(Satisfaction), y = valor)) +
geom_boxplot(fill = "lightblue") +
facet_wrap(~variable, scales = "free_y") +
labs(
title = "Variables numéricas vs Satisfaction",
x = "Satisfaction",
y = "Valor"
)
# Contrastes no paramétricos (Wilcoxon)
resultados_wilcoxon <- lapply(
vars_numericas,
function(var) {
wilcox.test(
train[[var]] ~ train[[response_var]]
)$p.value
}
)
names(resultados_wilcoxon) <- vars_numericas
resultados_wilcoxon
# 2. Variables categóricas vs Satisfaction
tablas_chi2 <- lapply(
vars_categoricas,
function(var) {
table(train[[var]], train[[response_var]])
}
)
names(tablas_chi2) <- vars_categoricas
tablas_chi2
# Test Chi-cuadrado
resultados_chi2 <- lapply(
vars_categoricas,
function(var) {
chisq.test(
table(train[[var]], train[[response_var]])
)$p.value
}
)
names(resultados_chi2) <- vars_categoricas
resultados_chi2
#Regresión logística
library(tidyverse)
library(effects)
install.packages("car")
library(car)
install.packages("pscl")
library(pscl)
# Cargar datos de entrenamiento
train <- read_csv("train.csv")
# Eliminar variable de registro si existe
if ("id" %in% names(train)) {
train <- train |> select(-id)
}
# Preparar variable respuesta
train <- train |>
mutate(Satisfaction = factor(Satisfaction))
# Eliminar observaciones con NA
train <- train |> drop_na()
# -------------------------
# Identificar variables
# -------------------------
vars_numericas <- train |>
dplyr::select(where(is.numeric)) |>
names()
vars_categoricas <- train |>
dplyr::select(where(~ !is.numeric(.))) |>
names() |>
setdiff("Satisfaction")
# Convertir categóricas a factor
train <- train |>
mutate(across(all_of(vars_categoricas), factor))
# -------------------------
# Modelo logístico base
# -------------------------
modelo_logit_base <- glm(
Satisfaction ~ .,
data = train,
family = binomial
)
summary(modelo_logit_base)
AIC(modelo_logit_base)
#Gráficos de efectos
plot(allEffects(modelo_logit_base))
#Contrastes globales
anova(modelo_logit_base, test = "Wald")
#Regresión logística
library(tidyverse)
library(effects)
install.packages("car")
library(car)
install.packages("pscl")
library(pscl)
# Cargar datos de entrenamiento
train <- read_csv("train.csv")
# Eliminar variable de registro si existe
if ("id" %in% names(train)) {
train <- train |> select(-id)
}
# Preparar variable respuesta
train <- train |>
mutate(Satisfaction = factor(Satisfaction))
# Eliminar observaciones con NA
train <- train |> drop_na()
# -------------------------
# Identificar variables
# -------------------------
vars_numericas <- train |>
dplyr::select(where(is.numeric)) |>
names()
vars_categoricas <- train |>
dplyr::select(where(~ !is.numeric(.))) |>
names() |>
setdiff("Satisfaction")
# Convertir categóricas a factor
train <- train |>
mutate(across(all_of(vars_categoricas), factor))
# -------------------------
# Modelo logístico base
# -------------------------
modelo_logit_base <- glm(
Satisfaction ~ .,
data = train,
family = binomial
)
summary(modelo_logit_base)
AIC(modelo_logit_base)
#Gráficos de efectos
plot(allEffects(modelo_logit_base))
#Contrastes globales
Anova(modelo_logit_base, test = "Wald")
anova(modelo_logit_base, test = "Chisq")
# -------------------------
# Modelo con no linealidad (polinomios grado 2)
# -------------------------
formula_poly <- as.formula(
paste(
"Satisfaction ~",
paste(
c(
paste0("poly(", vars_numericas, ", 2)"),
vars_categoricas
),
collapse = " + "
)
)
)
modelo_logit_poly <- glm(
formula_poly,
data = train,
family = binomial
)
summary(modelo_logit_poly)
AIC(modelo_logit_base, modelo_logit_poly)
plot(allEffects(modelo_logit_poly))
#Modelo con interacciones
modelo_logit_inter <- glm(
Satisfaction ~ Customer.Type * Class + Age + Flight.Distance,
data = train,
family = binomial
)
summary(modelo_logit_inter)
AIC(modelo_logit_base, modelo_logit_inter)
plot(allEffects(modelo_logit_inter))
# -------------------------
#Selección de modelo (stepwise, reducción de dimensionalidad en ambas direcciones)
# -------------------------
modelo_step <- step(modelo_logit_base, direction = "both")
summary(modelo_step)
AIC(modelo_step)
# Comparación de modelos
AIC(modelo_logit_base, modelo_logit_poly)
anova(modelo_logit_base, modelo_logit_poly, modelo_logit_inter, modelo_step, test = "Chisq")
# -------------------------
#Diagnósticos finales
# -------------------------
#Multicolinealidad
vif(modelo_step)
#Pseudo R2
pR2(modelo_step)
library(MASS)
library(kableExtra)
#Regresión logística
library(tidyverse)
library(effects)
library(car)
library(pscl)
# Cargar datos de entrenamiento
train <- read_csv("train.csv")
# Eliminar variable de registro si existe
if ("id" %in% names(train)) {
train <- train |> select(-id)
}
#Regresión logística
library(tidyverse)
library(effects)
library(car)
library(pscl)
# Cargar datos de entrenamiento
train <- read_csv("train.csv")
# Eliminar variable de registro si existe
if ("id" %in% names(train)) {
train <- train |> dplyr::select(-id)
}
# Preparar variable respuesta
train <- train |>
mutate(Satisfaction = factor(Satisfaction))
# Eliminar observaciones con NA
train <- train |> drop_na()
# -------------------------
# Identificar variables
# -------------------------
vars_numericas <- train |>
dplyr::select(where(is.numeric)) |>
names()
vars_categoricas <- train |>
dplyr::select(where(~ !is.numeric(.))) |>
names() |>
setdiff("Satisfaction")
# Convertir categóricas a factor
train <- train |>
mutate(across(all_of(vars_categoricas), factor))
# -------------------------
# Modelo logístico base
# -------------------------
modelo_logit_base <- glm(
Satisfaction ~ .,
data = train,
family = binomial
)
summary(modelo_logit_base)
AIC(modelo_logit_base)
#Gráficos de efectos
plot(allEffects(modelo_logit_base))
#Contrastes globales
Anova(modelo_logit_base, test = "Wald")
anova(modelo_logit_base, test = "Chisq")
# -------------------------
# Modelo con no linealidad (polinomios grado 2)
# -------------------------
formula_poly <- as.formula(
paste(
"Satisfaction ~",
paste(
c(
paste0("poly(", vars_numericas, ", 2)"),
vars_categoricas
),
collapse = " + "
)
)
)
modelo_logit_poly <- glm(
formula_poly,
data = train,
family = binomial
)
summary(modelo_logit_poly)
AIC(modelo_logit_base, modelo_logit_poly)
plot(allEffects(modelo_logit_poly))
#Modelo con interacciones
modelo_logit_inter <- glm(
Satisfaction ~ Customer.Type * Class + Age + Flight.Distance,
data = train,
family = binomial
)
summary(modelo_logit_inter)
AIC(modelo_logit_base, modelo_logit_inter)
plot(allEffects(modelo_logit_inter))
# -------------------------
#Selección de modelo (stepwise, reducción de dimensionalidad en ambas direcciones)
# -------------------------
modelo_step <- step(modelo_logit_base, direction = "both")
summary(modelo_step)
AIC(modelo_step)
# Comparación de modelos
AIC(modelo_logit_base, modelo_logit_poly)
anova(modelo_logit_base, modelo_logit_poly, modelo_logit_inter, modelo_step, test = "Chisq")
# -------------------------
#Diagnósticos finales
# -------------------------
#Multicolinealidad
vif(modelo_step)
#Pseudo R2
pR2(modelo_step)
#Regresión logística
library(tidyverse)
library(effects)
library(car)
library(pscl)
# Cargar datos de entrenamiento
train <- read_csv("train.csv")
# Eliminar variable de registro si existe
if ("id" %in% names(train)) {
train <- train |> dplyr::select(-id)
}
# Preparar variable respuesta
train <- train |>
mutate(Satisfaction = factor(Satisfaction))
# Eliminar observaciones con NA
train <- train |> drop_na()
# -------------------------
# Identificar variables
# -------------------------
vars_numericas <- train |>
dplyr::select(where(is.numeric)) |>
names()
vars_categoricas <- train |>
dplyr::select(where(~ !is.numeric(.))) |>
names() |>
setdiff("Satisfaction")
# Convertir categóricas a factor
train <- train |>
mutate(across(all_of(vars_categoricas), factor))
# -------------------------
# Modelo logístico base
# -------------------------
modelo_logit_base <- glm(
Satisfaction ~ .,
data = train,
family = binomial
)
summary(modelo_logit_base)
AIC(modelo_logit_base)
#Gráficos de efectos
plot(allEffects(modelo_logit_base))
#Contrastes globales
Anova(modelo_logit_base, test = "Wald")
anova(modelo_logit_base, test = "Chisq")
# -------------------------
# Modelo con no linealidad (polinomios grado 2)
# -------------------------
formula_poly <- as.formula(
paste(
"Satisfaction ~",
paste(
c(
paste0("poly(", vars_numericas, ", 2)"),
vars_categoricas
),
collapse = " + "
)
)
)
modelo_logit_poly <- glm(
formula_poly,
data = train,
family = binomial
)
summary(modelo_logit_poly)
AIC(modelo_logit_base, modelo_logit_poly)
plot(allEffects(modelo_logit_poly))
#Modelo con interacciones
modelo_logit_inter <- glm(
Satisfaction ~ Customer.Type * Class + Age + Flight.Distance,
data = train,
family = binomial
)
summary(modelo_logit_inter)
AIC(modelo_logit_base, modelo_logit_inter)
plot(allEffects(modelo_logit_inter))
# -------------------------
#Selección de modelo (stepwise, reducción de dimensionalidad en ambas direcciones)
# -------------------------
modelo_step <- step(modelo_logit_base, direction = "both")
summary(modelo_step)
AIC(modelo_step)
# Comparación de modelos
anova(modelo_logit_base, modelo_logit_poly, modelo_logit_inter, modelo_step, test = "Chisq")
# -------------------------
#Diagnósticos finales
# -------------------------
#Multicolinealidad
vif(modelo_step)
#Pseudo R2
pR2(modelo_step)
